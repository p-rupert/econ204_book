{"version":"1","records":[{"hierarchy":{"lvl1":"Dynamic Programming"},"type":"lvl1","url":"/dynamic-programming-lecture-egm-stochastic","position":0},{"hierarchy":{"lvl1":"Dynamic Programming"},"content":"Contents: Bellman equation, contraction mapping, Value Function Iteration (VFI), Policy Iteration, Endogenous Grid Method (EGM), numerical examples (VFI code) and exercises.\n\nThis notebook contains lecture notes (markdown) and runnable Python examples for the numerical sections.\n\n","type":"content","url":"/dynamic-programming-lecture-egm-stochastic","position":1},{"hierarchy":{"lvl1":"Dynamic Programming","lvl3":"Learning objectives"},"type":"lvl3","url":"/dynamic-programming-lecture-egm-stochastic#learning-objectives","position":2},{"hierarchy":{"lvl1":"Dynamic Programming","lvl3":"Learning objectives"},"content":"After working through this notebook, you should be able to:\n\nState and interpret the Bellman equation and the principle of optimality.\n\nSketch why the Bellman operator is a contraction and why a unique fixed point exists.\n\nImplement Value Function Iteration (VFI) for a simple stochastic consumptionâ€“savings problem.\n\nKnow advantages and limitations of alternative solution methods: policy iteration, EGM, collocation.\n\nConnect Bellman/Euler approaches and understand numerical tradeoffs.\n\n","type":"content","url":"/dynamic-programming-lecture-egm-stochastic#learning-objectives","position":3},{"hierarchy":{"lvl1":"Dynamic Programming","lvl2":"What is the Bellman equation?"},"type":"lvl2","url":"/dynamic-programming-lecture-egm-stochastic#what-is-the-bellman-equation","position":4},{"hierarchy":{"lvl1":"Dynamic Programming","lvl2":"What is the Bellman equation?"},"content":"The Bellman equation is the fundamental recursive identity in dynamic programming and Markov decision processes (MDPs).  It encodes the principle of optimality: the value of being in a state equals the best immediate reward plus the (discounted) value of the next state when following an optimal policy.\n\n","type":"content","url":"/dynamic-programming-lecture-egm-stochastic#what-is-the-bellman-equation","position":5},{"hierarchy":{"lvl1":"Dynamic Programming","lvl3":"Deterministic Bellman equation","lvl2":"What is the Bellman equation?"},"type":"lvl3","url":"/dynamic-programming-lecture-egm-stochastic#deterministic-bellman-equation","position":6},{"hierarchy":{"lvl1":"Dynamic Programming","lvl3":"Deterministic Bellman equation","lvl2":"What is the Bellman equation?"},"content":"State s\\in\\mathcal S, action a\\in\\mathcal A(s). Deterministic law s' = f(s,a). Discount factor 0<\\beta<1.\n\nThe Bellman equation:V(s)=\\max_{a\\in\\mathcal A(s)} \\{ u(s,a) + \\beta V(f(s,a)) \\}.\n\nExample (deterministic consumptionâ€“savings):State: assets a. Control: next-period assets a' (or consumption c). Budget: c = (1+r)a + y - a'.Bellman:V(a)=\\max_{a'\\ge\\underline a} \\{ u((1+r)a+y-a') + \\beta V(a') \\}.\n\nUsing the envelope theorem and FOC you can derive the Euler equation when interior.\n\n","type":"content","url":"/dynamic-programming-lecture-egm-stochastic#deterministic-bellman-equation","position":7},{"hierarchy":{"lvl1":"Dynamic Programming","lvl3":"General (discrete-time, stochastic) form","lvl2":"What is the Bellman equation?"},"type":"lvl3","url":"/dynamic-programming-lecture-egm-stochastic#general-discrete-time-stochastic-form","position":8},{"hierarchy":{"lvl1":"Dynamic Programming","lvl3":"General (discrete-time, stochastic) form","lvl2":"What is the Bellman equation?"},"content":"Let:\n\ns be the current state (from state space \\mathcal S),\n\na an action (from the action set \\mathcal A(s)),\n\nr(s,a) the immediate reward when taking a in s,\n\nP(s' \\mid s,a) the probability of next state s',\n\n\\beta \\in (0,1) the discount factor, and\n\nV(s) the value function (maximal expected discounted reward starting from s).\n\nThe Bellman optimality equation is\\boxed{\\,V(s) = \\max_{a\\in\\mathcal A(s)}\\left\\{ r(s,a) + \\beta \\sum_{s'} P(s'\\mid s,a)\\,V(s') \\right\\} \\,}\n\nFor a fixed policy \\pi the Bellman (policy) equation isV^\\pi(s) = r(s,\\pi(s)) + \\beta \\sum_{s'} P(s'\\mid s,\\pi(s))\\,V^\\pi(s').","type":"content","url":"/dynamic-programming-lecture-egm-stochastic#general-discrete-time-stochastic-form","position":9},{"hierarchy":{"lvl1":"Dynamic Programming","lvl2":"ðŸ° The Cake-Eating Problem"},"type":"lvl2","url":"/dynamic-programming-lecture-egm-stochastic#id-the-cake-eating-problem","position":10},{"hierarchy":{"lvl1":"Dynamic Programming","lvl2":"ðŸ° The Cake-Eating Problem"},"content":"Classic problem in programming: you are given a whole cake of some size k.\n\nHow should you choose a consumption stream?\n\nMaximize lifetime utility\n\nAccount for discounting\n\nThe cake will go bad at some point\n\nDynamic problems involve returns now vs. returns later.\n\nAn obvious tradeoff:\n\nDelaying consumption is costly (discount factor)\n\nBut delaying may be beneficial (due to concave utility)\n\n\\implies eat some today and some tomorrow\n\nHow much to eat today? (assume it goes bad in T days)\n\nall of it on day 1?\n\n1/T each day?\n\nBut youâ€™d rather eat more today than tomorrow.\n\nImplication: eat more on the first day, less and less on the following days.","type":"content","url":"/dynamic-programming-lecture-egm-stochastic#id-the-cake-eating-problem","position":11},{"hierarchy":{"lvl1":"Dynamic Programming","lvl2":"Analytical Solution of the Cake-Eating Problem"},"type":"lvl2","url":"/dynamic-programming-lecture-egm-stochastic#analytical-solution-of-the-cake-eating-problem","position":12},{"hierarchy":{"lvl1":"Dynamic Programming","lvl2":"Analytical Solution of the Cake-Eating Problem"},"content":"We start with a finite horizon T, an initial cake size k_0, and no uncertainty. The agent chooses a consumption sequence \\{c_t\\}_{t=0}^T.","type":"content","url":"/dynamic-programming-lecture-egm-stochastic#analytical-solution-of-the-cake-eating-problem","position":13},{"hierarchy":{"lvl1":"Dynamic Programming","lvl3":"1. Setup","lvl2":"Analytical Solution of the Cake-Eating Problem"},"type":"lvl3","url":"/dynamic-programming-lecture-egm-stochastic#id-1-setup","position":14},{"hierarchy":{"lvl1":"Dynamic Programming","lvl3":"1. Setup","lvl2":"Analytical Solution of the Cake-Eating Problem"},"content":"Initial cake: k_0 > 0 given.\n\nLaw of motion for the cake:\nk_{t+1} = k_t - c_t, \\quad t = 0,1,\\dots,T\n\nNo borrowing and no negative cake:\nc_t \\ge 0, \\quad k_t \\ge 0.\n\nCake spoils after date T, so it is optimal to end with no cake:\nk_{T+1} = 0.\n\nPreferences: CRRA utilityu(c_t) = \\frac{c_t^{1-\\gamma}}{1-\\gamma}, \\quad \\gamma > 0, \\ \\gamma \\ne 1,\n\nand discount factor 0 < \\beta < 1.\n\nThe agent maximizes:\\max_{\\{c_t\\}_{t=0}^T} \\; \\sum_{t=0}^T \\beta^t u(c_t)\n\nsubject to the cake dynamics and k_0 given.","type":"content","url":"/dynamic-programming-lecture-egm-stochastic#id-1-setup","position":15},{"hierarchy":{"lvl1":"Dynamic Programming","lvl3":"2. Intertemporal budget constraint","lvl2":"Analytical Solution of the Cake-Eating Problem"},"type":"lvl3","url":"/dynamic-programming-lecture-egm-stochastic#id-2-intertemporal-budget-constraint","position":16},{"hierarchy":{"lvl1":"Dynamic Programming","lvl3":"2. Intertemporal budget constraint","lvl2":"Analytical Solution of the Cake-Eating Problem"},"content":"Fromk_{t+1} = k_t - c_t\n\nwe can iterate forward:\n\nk_1 = k_0 - c_0\n\nk_2 = k_1 - c_1 = k_0 - c_0 - c_1\n\n...\n\nk_{T+1} = k_0 - \\sum_{t=0}^T c_t.\n\nImposing k_{T+1} = 0 gives:k_{T+1} = k_0 - \\sum_{t=0}^T c_t = 0\n\\quad \\Rightarrow \\quad\n\\sum_{t=0}^T c_t = k_0.\n\nSo the resource constraint is simply: total consumption over the T+1 periods equals the initial cake.","type":"content","url":"/dynamic-programming-lecture-egm-stochastic#id-2-intertemporal-budget-constraint","position":17},{"hierarchy":{"lvl1":"Dynamic Programming","lvl3":"3. Euler equation","lvl2":"Analytical Solution of the Cake-Eating Problem"},"type":"lvl3","url":"/dynamic-programming-lecture-egm-stochastic#id-3-euler-equation","position":18},{"hierarchy":{"lvl1":"Dynamic Programming","lvl3":"3. Euler equation","lvl2":"Analytical Solution of the Cake-Eating Problem"},"content":"We can write the Lagrangian (or rely on dynamic programming, same Euler):\n\nMaximize\\sum_{t=0}^T \\beta^t u(c_t)\n\nsubject to \\sum_{t=0}^T c_t = k_0.\n\nIntroduce a multiplier \\lambda on the resource constraint:\\mathcal{L} = \\sum_{t=0}^T \\beta^t u(c_t) + \\lambda \\left(k_0 - \\sum_{t=0}^T c_t\\right).\n\nFirst-order condition for each c_t:\\frac{\\partial \\mathcal{L}}{\\partial c_t}\n= \\beta^t u'(c_t) - \\lambda = 0\n\\quad \\Rightarrow \\quad\n\\beta^t u'(c_t) = \\lambda.\n\nFor CRRA,u'(c_t) = c_t^{-\\gamma}.\n\nSo\\beta^t c_t^{-\\gamma} = \\lambda.\n\nTake two adjacent periods, t and t+1:\\beta^t c_t^{-\\gamma} = \\lambda, \\qquad\n\\beta^{t+1} c_{t+1}^{-\\gamma} = \\lambda.\n\nSet them equal (since both equal \\lambda):\\beta^t c_t^{-\\gamma} = \\beta^{t+1} c_{t+1}^{-\\gamma}.\n\nDivide both sides by \\beta^t:c_t^{-\\gamma} = \\beta c_{t+1}^{-\\gamma}.\n\nRearrange:c_{t+1}^{-\\gamma} = \\beta^{-1} c_t^{-\\gamma}.\n\nRaise both sides to the power -1/\\gamma:c_{t+1} = \\beta^{1/\\gamma} c_t.\n\nThis is the Euler equation in this problem: consumption follows a geometric path.\n\nDefineg \\equiv \\beta^{1/\\gamma}, \\quad 0 < g < 1.\n\nThenc_{t+1} = g \\, c_t \\quad \\Rightarrow \\quad c_t = g^t c_0.\n\nSo consumption is geometrically declining over time.","type":"content","url":"/dynamic-programming-lecture-egm-stochastic#id-3-euler-equation","position":19},{"hierarchy":{"lvl1":"Dynamic Programming","lvl3":"4. Use the resource constraint to pin down c_0","lvl2":"Analytical Solution of the Cake-Eating Problem"},"type":"lvl3","url":"/dynamic-programming-lecture-egm-stochastic#id-4-use-the-resource-constraint-to-pin-down-c-0","position":20},{"hierarchy":{"lvl1":"Dynamic Programming","lvl3":"4. Use the resource constraint to pin down c_0","lvl2":"Analytical Solution of the Cake-Eating Problem"},"content":"We have:c_t = g^t c_0, \\quad t=0,\\dots,T,\n\nand the resource constraint:\\sum_{t=0}^T c_t = k_0.\n\nSubstitute the geometric sequence:\\sum_{t=0}^T c_t\n= \\sum_{t=0}^T g^t c_0\n= c_0 \\sum_{t=0}^T g^t\n= c_0 \\frac{1 - g^{T+1}}{1 - g}\n= k_0.\n\nSolve for c_0:c_0 = k_0 \\, \\frac{1 - g}{1 - g^{T+1}}.\n\nRecall g = \\beta^{1/\\gamma}, soc_0 = k_0 \\, \\frac{1 - \\beta^{1/\\gamma}}{1 - \\beta^{(T+1)/\\gamma}}.\n\nThen the entire path is:c_t = g^t c_0\n= \\beta^{t/\\gamma} \\, k_0 \\, \\frac{1 - \\beta^{1/\\gamma}}{1 - \\beta^{(T+1)/\\gamma}},\n\\quad t = 0,1,\\dots,T.\n\nThis is the analytic solution for the optimal consumption path.","type":"content","url":"/dynamic-programming-lecture-egm-stochastic#id-4-use-the-resource-constraint-to-pin-down-c-0","position":21},{"hierarchy":{"lvl1":"Dynamic Programming","lvl3":"5. Log-utility as a special case","lvl2":"Analytical Solution of the Cake-Eating Problem"},"type":"lvl3","url":"/dynamic-programming-lecture-egm-stochastic#id-5-log-utility-as-a-special-case","position":22},{"hierarchy":{"lvl1":"Dynamic Programming","lvl3":"5. Log-utility as a special case","lvl2":"Analytical Solution of the Cake-Eating Problem"},"content":"For log utility, u(c_t) = \\ln c_t, this corresponds to the limit \\gamma \\to 1.\n\nThe Euler equation becomes:u'(c_t) = \\frac{1}{c_t}, \\quad\n\\frac{1}{c_t} = \\beta \\, \\frac{1}{c_{t+1}}\n\\quad \\Rightarrow \\quad\nc_{t+1} = \\beta \\, c_t.\n\nSo now g = \\beta andc_t = \\beta^t c_0.\n\nThe resource constraint:\\sum_{t=0}^T c_t\n= c_0 \\sum_{t=0}^T \\beta^t\n= c_0 \\frac{1 - \\beta^{T+1}}{1 - \\beta}\n= k_0.\n\nHencec_0 = k_0 \\, \\frac{1 - \\beta}{1 - \\beta^{T+1}}.\n\nAnd the path:c_t = \\beta^t \\, k_0 \\, \\frac{1 - \\beta}{1 - \\beta^{T+1}}, \\quad t=0,\\dots,T.","type":"content","url":"/dynamic-programming-lecture-egm-stochastic#id-5-log-utility-as-a-special-case","position":23},{"hierarchy":{"lvl1":"Dynamic Programming","lvl3":"6. Infinite-horizon case (for completeness)","lvl2":"Analytical Solution of the Cake-Eating Problem"},"type":"lvl3","url":"/dynamic-programming-lecture-egm-stochastic#id-6-infinite-horizon-case-for-completeness","position":24},{"hierarchy":{"lvl1":"Dynamic Programming","lvl3":"6. Infinite-horizon case (for completeness)","lvl2":"Analytical Solution of the Cake-Eating Problem"},"content":"If we let T \\to \\infty, the cake never â€œspoils,â€ but the horizon is infinite and discounting ensures finite utility.\n\nFor 0 < g < 1, the infinite geometric sum is:\\sum_{t=0}^\\infty g^t = \\frac{1}{1-g}.\n\nThe resource constraint \\sum_{t=0}^\\infty c_t = k_0 becomes:c_0 \\frac{1}{1 - g} = k_0\n\\quad \\Rightarrow \\quad\nc_0 = (1 - g) k_0.\n\nSoc_t = g^t c_0 = g^t (1 - g) k_0.\n\nSubstitute g = \\beta^{1/\\gamma}:c_t = \\beta^{t/\\gamma} (1 - \\beta^{1/\\gamma}) k_0.\n\nFor log utility (\\gamma = 1), this becomes:c_t = \\beta^t (1 - \\beta) k_0.","type":"content","url":"/dynamic-programming-lecture-egm-stochastic#id-6-infinite-horizon-case-for-completeness","position":25},{"hierarchy":{"lvl1":"Dynamic Programming","lvl3":"7. Summary of the analytical solution","lvl2":"Analytical Solution of the Cake-Eating Problem"},"type":"lvl3","url":"/dynamic-programming-lecture-egm-stochastic#id-7-summary-of-the-analytical-solution","position":26},{"hierarchy":{"lvl1":"Dynamic Programming","lvl3":"7. Summary of the analytical solution","lvl2":"Analytical Solution of the Cake-Eating Problem"},"content":"Euler equation (CRRA):c_{t+1} = \\beta^{1/\\gamma} c_t.\n\nFinite-horizon optimal consumption path:c_t = \\beta^{t/\\gamma} \\, k_0 \\, \\frac{1 - \\beta^{1/\\gamma}}{1 - \\beta^{(T+1)/\\gamma}}, \n\\quad t = 0,\\dots,T.\n\nLog-utility special case (\\gamma = 1):c_t = \\beta^t \\, k_0 \\, \\frac{1 - \\beta}{1 - \\beta^{T+1}}.\n\nInfinite horizon (no spoilage, but discounting):c_t = \\beta^{t/\\gamma} (1 - \\beta^{1/\\gamma}) k_0,\n\nand, for log utility,c_t = \\beta^t (1 - \\beta) k_0.\n\nThis is the full analytic solution of the cake-eating problem: the optimal consumption path is geometric, determined by the discount factor \\beta, the curvature \\gamma, the horizon T, and the initial cake size k_0.","type":"content","url":"/dynamic-programming-lecture-egm-stochastic#id-7-summary-of-the-analytical-solution","position":27},{"hierarchy":{"lvl1":"Dynamic Programming","lvl2":"ðŸ’¡ A simple example"},"type":"lvl2","url":"/dynamic-programming-lecture-egm-stochastic#id-a-simple-example","position":28},{"hierarchy":{"lvl1":"Dynamic Programming","lvl2":"ðŸ’¡ A simple example"},"content":"Preferences: u(c_t) = \\ln(c_t)\n\nspecifically, CRRA preferences:u(c_t) = \\frac{c_t^{1 - \\gamma}}{1 - \\gamma}, \\quad (\\gamma > 0, \\, \\gamma \\ne 1)\n\nwhere c_t is the amount of cake eaten at time t.\n\nDiscount factor: \\beta < 1\n\nCurvature of utility: \\gamma\n\nThe present value of the consumption stream is:W(c_1, c_2, \\ldots, c_T) = \\sum_{t=1}^{T} \\beta^t u(c_t)\n\nGoal: maximize W by choosing the sequence \\{ c_t \\}.\n\nSize of cake at time t:k_{t+1} = k_t - c_t\n\nAnd, of course, k_t \\ge 0.\n\nLet V(k) be the maximum lifetime utility attainable when you have k units of cake left:V(k) = \\max \\sum_{t=0}^{\\infty} \\beta^t u(c_t)","type":"content","url":"/dynamic-programming-lecture-egm-stochastic#id-a-simple-example","position":29},{"hierarchy":{"lvl1":"Dynamic Programming","lvl3":"The Bellman equation","lvl2":"ðŸ’¡ A simple example"},"type":"lvl3","url":"/dynamic-programming-lecture-egm-stochastic#the-bellman-equation","position":30},{"hierarchy":{"lvl1":"Dynamic Programming","lvl3":"The Bellman equation","lvl2":"ðŸ’¡ A simple example"},"content":"The value function V(k) satisfies the Bellman equation:V(k) = \\max_{0 \\le c \\le k} \\{ u(c) + \\beta V(k - c) \\}, \\quad \\text{for any given } k \\ge 0\n\nWhere:\n\nk_t is the state variable\n\nc_t is the control (action) variable\n\n\\beta and \\gamma are parameters","type":"content","url":"/dynamic-programming-lecture-egm-stochastic#the-bellman-equation","position":31},{"hierarchy":{"lvl1":"Dynamic Programming","lvl3":"First-order conditions","lvl2":"ðŸ’¡ A simple example"},"type":"lvl3","url":"/dynamic-programming-lecture-egm-stochastic#first-order-conditions","position":32},{"hierarchy":{"lvl1":"Dynamic Programming","lvl3":"First-order conditions","lvl2":"ðŸ’¡ A simple example"},"content":"Substitute the constraint into the objective function:\\beta^t u(k_{t-1} - k_t) + \\beta^{t+1} u(k_t - k_{t+1})","type":"content","url":"/dynamic-programming-lecture-egm-stochastic#first-order-conditions","position":33},{"hierarchy":{"lvl1":"Dynamic Programming","lvl2":"âœ… Deriving the Euler Equation in the Cake-Eating Problem"},"type":"lvl2","url":"/dynamic-programming-lecture-egm-stochastic#id-deriving-the-euler-equation-in-the-cake-eating-problem","position":34},{"hierarchy":{"lvl1":"Dynamic Programming","lvl2":"âœ… Deriving the Euler Equation in the Cake-Eating Problem"},"content":"We start with the objective for two adjacent periods after substituting the resource constraint:\\beta^{t} u(k_{t-1} - k_t) + \\beta^{t+1} u(k_t - k_{t+1})\n\nDefine consumptions asc_{t-1} = k_{t-1} - k_t, \\qquad c_t = k_t - k_{t+1}.\n\nSo the objective can be written as\\beta^{t} u(c_{t-1}) + \\beta^{t+1} u(c_t).\n\nWe now take the derivative with respect to k_t.","type":"content","url":"/dynamic-programming-lecture-egm-stochastic#id-deriving-the-euler-equation-in-the-cake-eating-problem","position":35},{"hierarchy":{"lvl1":"Dynamic Programming","lvl4":"Step 1. Derivative of the first term","lvl2":"âœ… Deriving the Euler Equation in the Cake-Eating Problem"},"type":"lvl4","url":"/dynamic-programming-lecture-egm-stochastic#step-1-derivative-of-the-first-term","position":36},{"hierarchy":{"lvl1":"Dynamic Programming","lvl4":"Step 1. Derivative of the first term","lvl2":"âœ… Deriving the Euler Equation in the Cake-Eating Problem"},"content":"\\frac{\\partial}{\\partial k_t} \\big[\\beta^{t} u(k_{t-1} - k_t)\\big]\n= \\beta^{t} u'(k_{t-1} - k_t) \\cdot \\frac{\\partial (k_{t-1} - k_t)}{\\partial k_t}.\n\nSince \\frac{\\partial (k_{t-1} - k_t)}{\\partial k_t} = -1, this becomes- \\beta^{t} u'(k_{t-1} - k_t)\n= - \\beta^{t} u'(c_{t-1}).","type":"content","url":"/dynamic-programming-lecture-egm-stochastic#step-1-derivative-of-the-first-term","position":37},{"hierarchy":{"lvl1":"Dynamic Programming","lvl4":"Step 2. Derivative of the second term","lvl2":"âœ… Deriving the Euler Equation in the Cake-Eating Problem"},"type":"lvl4","url":"/dynamic-programming-lecture-egm-stochastic#step-2-derivative-of-the-second-term","position":38},{"hierarchy":{"lvl1":"Dynamic Programming","lvl4":"Step 2. Derivative of the second term","lvl2":"âœ… Deriving the Euler Equation in the Cake-Eating Problem"},"content":"\\frac{\\partial}{\\partial k_t} \\big[\\beta^{t+1} u(k_t - k_{t+1})\\big]\n= \\beta^{t+1} u'(k_t - k_{t+1}) \\cdot \\frac{\\partial (k_t - k_{t+1})}{\\partial k_t}.\n\nHere \\frac{\\partial (k_t - k_{t+1})}{\\partial k_t} = 1, so we get\\beta^{t+1} u'(k_t - k_{t+1})\n= \\beta^{t+1} u'(c_t).","type":"content","url":"/dynamic-programming-lecture-egm-stochastic#step-2-derivative-of-the-second-term","position":39},{"hierarchy":{"lvl1":"Dynamic Programming","lvl4":"Step 3. First-order condition","lvl2":"âœ… Deriving the Euler Equation in the Cake-Eating Problem"},"type":"lvl4","url":"/dynamic-programming-lecture-egm-stochastic#step-3-first-order-condition","position":40},{"hierarchy":{"lvl1":"Dynamic Programming","lvl4":"Step 3. First-order condition","lvl2":"âœ… Deriving the Euler Equation in the Cake-Eating Problem"},"content":"Add the two derivatives and set equal to zero:- \\beta^{t} u'(c_{t-1}) + \\beta^{t+1} u'(c_t) = 0.\n\nSimplify:\\beta^{t+1} u'(c_t) = \\beta^{t} u'(c_{t-1})\n\\quad \\Rightarrow \\quad\nu'(c_{t-1}) = \\beta u'(c_t).","type":"content","url":"/dynamic-programming-lecture-egm-stochastic#step-3-first-order-condition","position":41},{"hierarchy":{"lvl1":"Dynamic Programming","lvl4":"Step 4. Euler equation (general form)","lvl2":"âœ… Deriving the Euler Equation in the Cake-Eating Problem"},"type":"lvl4","url":"/dynamic-programming-lecture-egm-stochastic#step-4-euler-equation-general-form","position":42},{"hierarchy":{"lvl1":"Dynamic Programming","lvl4":"Step 4. Euler equation (general form)","lvl2":"âœ… Deriving the Euler Equation in the Cake-Eating Problem"},"content":"Relabel indices (replace t-1 by t) to obtain the standard Euler equation:u'(c_t) = \\beta u'(c_{t+1}).","type":"content","url":"/dynamic-programming-lecture-egm-stochastic#step-4-euler-equation-general-form","position":43},{"hierarchy":{"lvl1":"Dynamic Programming","lvl4":"ðŸ’¡ Interpretation","lvl2":"âœ… Deriving the Euler Equation in the Cake-Eating Problem"},"type":"lvl4","url":"/dynamic-programming-lecture-egm-stochastic#id-interpretation","position":44},{"hierarchy":{"lvl1":"Dynamic Programming","lvl4":"ðŸ’¡ Interpretation","lvl2":"âœ… Deriving the Euler Equation in the Cake-Eating Problem"},"content":"The Euler equation equates the marginal utility of consuming today with the discounted marginal utility of consuming tomorrow.\n\nIt describes the optimal intertemporal tradeoff between consuming now and saving for later.\n\nWith CRRA utility u(c) = \\frac{c^{1-\\gamma}}{1-\\gamma}, it impliesc_{t+1} = \\beta^{1/\\gamma} c_t,\n\n\nso consumption declines geometrically over time.","type":"content","url":"/dynamic-programming-lecture-egm-stochastic#id-interpretation","position":45},{"hierarchy":{"lvl1":"Dynamic Programming","lvl3":"Solution","lvl2":"âœ… Deriving the Euler Equation in the Cake-Eating Problem"},"type":"lvl3","url":"/dynamic-programming-lecture-egm-stochastic#solution","position":46},{"hierarchy":{"lvl1":"Dynamic Programming","lvl3":"Solution","lvl2":"âœ… Deriving the Euler Equation in the Cake-Eating Problem"},"content":"Using CRRA utility:c_{t+1} = \\beta \\, c_t\n\nSolve this backward in time.\n\nIn the optimum, no cake should be left over: k_{T+1} = 0.\n\nSo c_T = k_T.\n\nBy recursive substitution, the initial consumption is:c_0 = \\frac{1 - \\beta}{1 - \\beta^{T+1}} \\, k_0\n\nAnd using c_{t+1} = \\beta c_t, we can find the entire path of consumption over time.","type":"content","url":"/dynamic-programming-lecture-egm-stochastic#solution","position":47},{"hierarchy":{"lvl1":"Dynamic Programming","lvl3":"Summary","lvl2":"âœ… Deriving the Euler Equation in the Cake-Eating Problem"},"type":"lvl3","url":"/dynamic-programming-lecture-egm-stochastic#summary","position":48},{"hierarchy":{"lvl1":"Dynamic Programming","lvl3":"Summary","lvl2":"âœ… Deriving the Euler Equation in the Cake-Eating Problem"},"content":"The cake-eating problem illustrates intertemporal choice:\n\nTradeoff between consuming today vs. saving for tomorrow.\n\nDiscounting captures impatience.\n\nConcavity captures diminishing marginal utility.\n\nThe Bellman equation formulation:v(k) = \\max_{0 \\le c \\le k} \\{ u(c) + \\beta v(k - c) \\}\n\nprovides the foundation for dynamic programming and recursive methods in economics.\n\nfrom IPython.display import display, HTML\ndisplay(HTML(\"<style>.container { width:100% !important; }</style>\"))\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport math as m\nfrom scipy import stats as st\nfrom scipy import optimize\nfrom scipy.optimize import minimize_scalar, bisect\nfrom typing import NamedTuple\nimport time            # Imports system time module to time your script\n\nplt.close('all')  # close all open figures\n\nT = 9\nbeta = 0.96\nkv = np.zeros(T+1,float)\ncv = np.zeros(T+1,float)\nuv = np.zeros(T+1,float)\nkv[0] = 100  # k0\ncv[0] = (1.0-beta)/(1.0-beta**(T+1)) * kv[0]  # c0\nuv[0] = np.log(cv[0])\n\nfor i in range(1,T+1):\n    #print \"i=\" + str(i)\n    cv[i] = beta * cv[i-1]\n    kv[i] = kv[i-1] - cv[i-1]\n\n    # Period utility with discounting\n    uv[i] = beta**i *np.log(cv[i])\n\nnp.sum(uv)  # total utility\n\nprint(\"cv = \" + str(cv))\nprint(\"kv = \" + str(kv))\n\n\n\nfig, ax = plt.subplots(2,1)\nplt.subplots_adjust(wspace=0.4, hspace=0.8)\n#\nax[0].plot(cv, '-o')\nax[0].set_ylabel(r'$c^*_t$')\nax[0].set_xlabel('Period t')\nax[0].set_title('Optimal Consumption')\n#\nax[1].plot(kv, '-o')\nax[1].set_ylabel(r'$k_t$')\nax[1].set_xlabel('Period t')\nax[1].set_title('Cake size')\n#\nplt.show()\n\n\n\nFrom the lecture notes and using u(c_{t}) = \\frac{c^{1-\\gamma}}{1-\\gamma}, \\: (\\gamma > 0, \\gamma \\ne 1) as the utility function, the maximization problem gives the solution as v^{*}v^{*}(k) = \\left(1-\\beta^{1/\\gamma}\\right)^{-\\gamma} u(k),\n\nthat solves the Bellman equation and therefore equals the value function. Note that this analytic solution is only possible due to the CRRA preferences. We can explore this a little deeper using Python to understand what is going on. The utility function and value function in Python:\n\ndef u(c, Î³):\n\n    return c**(1 - Î³) / (1 - Î³)\ndef v_star(k, Î², Î³):\n\n    return (1 - Î²**(1 / Î³))**(-Î³) * u(k, Î³)\n\n\n\nLetâ€™s see this function for some parameters.\n\nÎ², Î³ = 0.95, 1.2\nk_grid = np.linspace(0.1, 5, 100)\n\nfig, ax = plt.subplots()\n\nax.plot(k_grid, v_star(k_grid, Î², Î³), label='value function')\n\nax.set_xlabel('$k$', fontsize=12)\nax.legend(fontsize=12)\n\nplt.show()\n\n\n\nHomework. You have now seen how to solve the deterministic case. Suppose you have a sneaky sister who pops in randomly and eats some of the cake. With some probability when you go to get some cake there is less there than you remembered.\n\n(A) Intuition...how will this affect your eating of the cake? That is, given the size of the cake you are left with, should you eat more or less compared to the no sister case?\n\n(B) Write some python code to explore this problem. Is your intuition correct? If so, is it really correct? If not, why not?\n\n","type":"content","url":"/dynamic-programming-lecture-egm-stochastic#summary","position":49},{"hierarchy":{"lvl1":"Dynamic Programming","lvl3":"Deterministic Bellman equation in a standard consumption choice model","lvl2":"âœ… Deriving the Euler Equation in the Cake-Eating Problem"},"type":"lvl3","url":"/dynamic-programming-lecture-egm-stochastic#deterministic-bellman-equation-in-a-standard-consumption-choice-model","position":50},{"hierarchy":{"lvl1":"Dynamic Programming","lvl3":"Deterministic Bellman equation in a standard consumption choice model","lvl2":"âœ… Deriving the Euler Equation in the Cake-Eating Problem"},"content":"State s\\in\\mathcal S, action a\\in\\mathcal A(s). Deterministic law s' = f(s,a). Discount factor 0<\\beta<1.\n\nThe Bellman equation:V(s)=\\max_{a\\in\\mathcal A(s)} \\{ u(s,a) + \\beta V(f(s,a)) \\}.\n\nExample (deterministic consumptionâ€“savings):State: assets a. Control: next-period assets a' (or consumption c). Budget: c = (1+r)a + y - a'.Bellman:V(a)=\\max_{a'\\ge\\underline a} \\{ u((1+r)a+y-a') + \\beta V(a') \\}.\n\nUsing the envelope theorem and FOC you can derive the Euler equation when interior.\n\n","type":"content","url":"/dynamic-programming-lecture-egm-stochastic#deterministic-bellman-equation-in-a-standard-consumption-choice-model","position":51},{"hierarchy":{"lvl1":"Dynamic Programming","lvl3":"Stochastic Bellman equation","lvl2":"âœ… Deriving the Euler Equation in the Cake-Eating Problem"},"type":"lvl3","url":"/dynamic-programming-lecture-egm-stochastic#stochastic-bellman-equation","position":52},{"hierarchy":{"lvl1":"Dynamic Programming","lvl3":"Stochastic Bellman equation","lvl2":"âœ… Deriving the Euler Equation in the Cake-Eating Problem"},"content":"With Markov income shock y_t and assets a_t:V(a,y)=\\max_{a'\\ge\\underline a} \\{ u((1+r)a + y - a') + \\beta \\sum_{y'} P(y'|y) V(a',y') \\}.\n\nWe typically discretize assets and the shock support, then compute the Bellman operator on the finite grid.\n\n","type":"content","url":"/dynamic-programming-lecture-egm-stochastic#stochastic-bellman-equation","position":53},{"hierarchy":{"lvl1":"Dynamic Programming","lvl2":"Contraction Mappings: Intuition and Simple Examples"},"type":"lvl2","url":"/dynamic-programming-lecture-egm-stochastic#contraction-mappings-intuition-and-simple-examples","position":54},{"hierarchy":{"lvl1":"Dynamic Programming","lvl2":"Contraction Mappings: Intuition and Simple Examples"},"content":"A contraction mapping is a function that brings points closer together every time you apply it.\n\nFormally, a function  T: X \\to X  on a space with distance  d(\\cdot,\\cdot)  is a contraction if:d(T(x), T(y)) \\le \\beta \\, d(x,y) \\quad \\forall x,y \\in X, \\quad \\text{for some } 0 \\le \\beta < 1.\n\nKey properties:\n\nMonotonicity: if x\\ge y then Tx\\ge Ty.\n\nContraction: \\|Tx-Ty\\|_\\infty \\le \\beta \\|x-y\\|_\\infty, so with 0<\\beta<1 Banach fixed-point gives a unique solution and geometric convergence of iterates.","type":"content","url":"/dynamic-programming-lecture-egm-stochastic#contraction-mappings-intuition-and-simple-examples","position":55},{"hierarchy":{"lvl1":"Dynamic Programming","lvl3":"Why is this important?","lvl2":"Contraction Mappings: Intuition and Simple Examples"},"type":"lvl3","url":"/dynamic-programming-lecture-egm-stochastic#why-is-this-important","position":56},{"hierarchy":{"lvl1":"Dynamic Programming","lvl3":"Why is this important?","lvl2":"Contraction Mappings: Intuition and Simple Examples"},"content":"The Contraction Mapping Theorem (Banach Fixed Point Theorem) says:\n\nIf T is a contraction on a complete space (X,d), then:\n\nThere exists a unique fixed point x^* such that T(x^*) = x^*.\n\nStarting from any initial x_{0}, repeated iteration x_{n+1} = T(x_n) converges to x^*.\n\nThis is the foundation of dynamic programming â€” the Bellman operator is a contraction, and its fixed point is the unique value function V^{*}.","type":"content","url":"/dynamic-programming-lecture-egm-stochastic#why-is-this-important","position":57},{"hierarchy":{"lvl1":"Dynamic Programming","lvl3":"Example 1: A Simple Shrinking Function","lvl2":"Contraction Mappings: Intuition and Simple Examples"},"type":"lvl3","url":"/dynamic-programming-lecture-egm-stochastic#example-1-a-simple-shrinking-function","position":58},{"hierarchy":{"lvl1":"Dynamic Programming","lvl3":"Example 1: A Simple Shrinking Function","lvl2":"Contraction Mappings: Intuition and Simple Examples"},"content":"Let T(x) = 0.5x.Then:|T(x) - T(y)| = 0.5|x - y| \\implies \\beta = 0.5.\n\nItâ€™s a contraction, and the fixed point satisfies x = 0.5x \\to x^* = 0.\n\nDefine operator T on bounded functions:(Tv)(s) = \\sup_{a\\in\\mathcal A(s)} \\{ u(s,a) + \\beta \\mathbb{E}[v(s')\\mid s,a] \\}.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Example 1: T(x) = 0.5x\nT = lambda x: 0.5 * x\nx_vals = np.linspace(-10, 10, 200)\n\nplt.figure(figsize=(6,4))\nplt.plot(x_vals, T(x_vals), label=\"T(x) = 0.5x\")\nplt.plot(x_vals, x_vals, 'k--', label=\"45Â° line (fixed points)\")\nplt.title(\"Contraction Example 1: T(x) = 0.5x\")\nplt.xlabel(\"x\")\nplt.ylabel(\"T(x)\")\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n","type":"content","url":"/dynamic-programming-lecture-egm-stochastic#example-1-a-simple-shrinking-function","position":59},{"hierarchy":{"lvl1":"Dynamic Programming","lvl3":"Example 2: Adding a Constant","lvl2":"Contraction Mappings: Intuition and Simple Examples"},"type":"lvl3","url":"/dynamic-programming-lecture-egm-stochastic#example-2-adding-a-constant","position":60},{"hierarchy":{"lvl1":"Dynamic Programming","lvl3":"Example 2: Adding a Constant","lvl2":"Contraction Mappings: Intuition and Simple Examples"},"content":"Let (T(x) = 0.5x + 2.\n\nThen:|T(x) - T(y)| = 0.5|x - y| \\implies \\beta = 0.5.\n\nSo itâ€™s still a contraction, but now the fixed point satisfies x = 0.5x + 2 \\to x^* = 4.\n\n# Example 2: T(x) = 0.5x + 2\nT = lambda x: 0.5 * x + 2\n\n# Iterate starting from any x0\nx0 = 0\nx_vals = [x0]\nfor _ in range(10):\n    x_vals.append(T(x_vals[-1]))\n\nprint(\"Fixed point should be 4\")\nprint(\"Iterates:\", x_vals)\n\n\n\n","type":"content","url":"/dynamic-programming-lecture-egm-stochastic#example-2-adding-a-constant","position":61},{"hierarchy":{"lvl1":"Dynamic Programming","lvl2":"ðŸ“˜ Conditions for a Contraction Mapping"},"type":"lvl2","url":"/dynamic-programming-lecture-egm-stochastic#id-conditions-for-a-contraction-mapping","position":62},{"hierarchy":{"lvl1":"Dynamic Programming","lvl2":"ðŸ“˜ Conditions for a Contraction Mapping"},"content":"A contraction mapping is a function that brings points closer together every time it is applied.\n\nFormally, let (X, d) be a metric space.A mapping T: X \\to X is a contraction if there exists a constant 0 \\leq \\beta < 1 such that\n\nd(T(x), T(y)) \\leq \\beta \\, d(x, y)  for all  x, y \\in X.\n\nHere, \\beta is called the contraction modulus â€” it measures how much the mapping shrinks distances.","type":"content","url":"/dynamic-programming-lecture-egm-stochastic#id-conditions-for-a-contraction-mapping","position":63},{"hierarchy":{"lvl1":"Dynamic Programming","lvl3":"ðŸ§© Necessary Conditions (for Banachâ€™s Fixed Point Theorem)","lvl2":"ðŸ“˜ Conditions for a Contraction Mapping"},"type":"lvl3","url":"/dynamic-programming-lecture-egm-stochastic#id-necessary-conditions-for-banachs-fixed-point-theorem","position":64},{"hierarchy":{"lvl1":"Dynamic Programming","lvl3":"ðŸ§© Necessary Conditions (for Banachâ€™s Fixed Point Theorem)","lvl2":"ðŸ“˜ Conditions for a Contraction Mapping"},"content":"For the Contraction Mapping Theorem (also called the Banach Fixed Point Theorem) to apply, the following conditions must hold:","type":"content","url":"/dynamic-programming-lecture-egm-stochastic#id-necessary-conditions-for-banachs-fixed-point-theorem","position":65},{"hierarchy":{"lvl1":"Dynamic Programming","lvl4":"1ï¸âƒ£ The space must be complete","lvl3":"ðŸ§© Necessary Conditions (for Banachâ€™s Fixed Point Theorem)","lvl2":"ðŸ“˜ Conditions for a Contraction Mapping"},"type":"lvl4","url":"/dynamic-programming-lecture-egm-stochastic#id-1-the-space-must-be-complete","position":66},{"hierarchy":{"lvl1":"Dynamic Programming","lvl4":"1ï¸âƒ£ The space must be complete","lvl3":"ðŸ§© Necessary Conditions (for Banachâ€™s Fixed Point Theorem)","lvl2":"ðŸ“˜ Conditions for a Contraction Mapping"},"content":"The space (X, d) must be complete â€” meaning every Cauchy sequence in X converges to a point that is also in X.\n\nExample: \\mathbb{R} with d(x,y) = |x-y| is complete âœ…\n\nExample: \\mathbb{Q} (rational numbers) is not complete âŒ (some Cauchy sequences converge to irrational limits)","type":"content","url":"/dynamic-programming-lecture-egm-stochastic#id-1-the-space-must-be-complete","position":67},{"hierarchy":{"lvl1":"Dynamic Programming","lvl4":"2ï¸âƒ£ The mapping must map the space into itself","lvl3":"ðŸ§© Necessary Conditions (for Banachâ€™s Fixed Point Theorem)","lvl2":"ðŸ“˜ Conditions for a Contraction Mapping"},"type":"lvl4","url":"/dynamic-programming-lecture-egm-stochastic#id-2-the-mapping-must-map-the-space-into-itself","position":68},{"hierarchy":{"lvl1":"Dynamic Programming","lvl4":"2ï¸âƒ£ The mapping must map the space into itself","lvl3":"ðŸ§© Necessary Conditions (for Banachâ€™s Fixed Point Theorem)","lvl2":"ðŸ“˜ Conditions for a Contraction Mapping"},"content":"For all x \\in X, we must have T(x) \\in X.\n\nThat is, T takes elements of X and returns elements still in X.\n\nExample: If X = [0,1] and T(x) = 0.5x + 0.5, then T(x) \\in [0.5,1] \\subseteq [0,1], so it maps the interval into itself âœ….","type":"content","url":"/dynamic-programming-lecture-egm-stochastic#id-2-the-mapping-must-map-the-space-into-itself","position":69},{"hierarchy":{"lvl1":"Dynamic Programming","lvl4":"3ï¸âƒ£ The mapping must shrink distances","lvl3":"ðŸ§© Necessary Conditions (for Banachâ€™s Fixed Point Theorem)","lvl2":"ðŸ“˜ Conditions for a Contraction Mapping"},"type":"lvl4","url":"/dynamic-programming-lecture-egm-stochastic#id-3-the-mapping-must-shrink-distances","position":70},{"hierarchy":{"lvl1":"Dynamic Programming","lvl4":"3ï¸âƒ£ The mapping must shrink distances","lvl3":"ðŸ§© Necessary Conditions (for Banachâ€™s Fixed Point Theorem)","lvl2":"ðŸ“˜ Conditions for a Contraction Mapping"},"content":"There must exist a constant \\beta with 0 \\le \\beta < 1 such that\n\nd(T(x), T(y)) \\le \\beta \\, d(x, y)  for all  x, y \\in X.\n\nThis ensures that the function pulls points closer together with each application.\n\nExample: T(x) = 0.5x + 2 satisfies|T(x) - T(y)| = 0.5|x - y|,so \\beta = 0.5 < 1 â€” it is a contraction âœ….","type":"content","url":"/dynamic-programming-lecture-egm-stochastic#id-3-the-mapping-must-shrink-distances","position":71},{"hierarchy":{"lvl1":"Dynamic Programming","lvl4":"4ï¸âƒ£ (Optional but common) The mapping is continuous","lvl3":"ðŸ§© Necessary Conditions (for Banachâ€™s Fixed Point Theorem)","lvl2":"ðŸ“˜ Conditions for a Contraction Mapping"},"type":"lvl4","url":"/dynamic-programming-lecture-egm-stochastic#id-4-optional-but-common-the-mapping-is-continuous","position":72},{"hierarchy":{"lvl1":"Dynamic Programming","lvl4":"4ï¸âƒ£ (Optional but common) The mapping is continuous","lvl3":"ðŸ§© Necessary Conditions (for Banachâ€™s Fixed Point Theorem)","lvl2":"ðŸ“˜ Conditions for a Contraction Mapping"},"content":"While continuity is not required for Banachâ€™s theorem, most contraction mappings encountered in practice (especially in economics or numerical analysis) are continuous.","type":"content","url":"/dynamic-programming-lecture-egm-stochastic#id-4-optional-but-common-the-mapping-is-continuous","position":73},{"hierarchy":{"lvl1":"Dynamic Programming","lvl3":"âœ… Summary Table","lvl2":"ðŸ“˜ Conditions for a Contraction Mapping"},"type":"lvl3","url":"/dynamic-programming-lecture-egm-stochastic#id-summary-table","position":74},{"hierarchy":{"lvl1":"Dynamic Programming","lvl3":"âœ… Summary Table","lvl2":"ðŸ“˜ Conditions for a Contraction Mapping"},"content":"Condition\n\nMeaning\n\nExample\n\nCompleteness\n\n(X, d) is complete\n\n\\mathbb{R} with $\n\nSelf-mapping\n\nT(x) \\in X for all x\n\nT:[0,1]\\to[0,1]\n\nDistance shrinking\n\nd(T(x),T(y)) \\le \\beta d(x,y) with \\beta<1\n\nT(x)=0.5x+2\n\nContinuity (optional)\n\nSmooth, no jumps\n\nContinuous T(x)","type":"content","url":"/dynamic-programming-lecture-egm-stochastic#id-summary-table","position":75},{"hierarchy":{"lvl1":"Dynamic Programming","lvl3":"ðŸ’¡ Economic Example: Bellman Operator","lvl2":"ðŸ“˜ Conditions for a Contraction Mapping"},"type":"lvl3","url":"/dynamic-programming-lecture-egm-stochastic#id-economic-example-bellman-operator","position":76},{"hierarchy":{"lvl1":"Dynamic Programming","lvl3":"ðŸ’¡ Economic Example: Bellman Operator","lvl2":"ðŸ“˜ Conditions for a Contraction Mapping"},"content":"In dynamic programming, the Bellman operator\n\n(TV)(x) = \\max_a \\{ u(x,a) + \\beta \\, \\mathbb{E}[V(f(x,a,\\varepsilon))] \\}\n\nis a contraction with modulus \\beta when 0 < \\beta < 1 and V is bounded.\n\nThen,\n\n\\| T(V_1) - T(V_2) \\|_\\infty \\le \\beta \\, \\| V_1 - V_2 \\|_\\infty,\n\nwhich means repeated application V_{n+1} = T(V_n) converges to the unique value function V^* satisfying V^* = T(V^*).","type":"content","url":"/dynamic-programming-lecture-egm-stochastic#id-economic-example-bellman-operator","position":77},{"hierarchy":{"lvl1":"Dynamic Programming","lvl3":"ðŸ§  Key Takeaway","lvl2":"ðŸ“˜ Conditions for a Contraction Mapping"},"type":"lvl3","url":"/dynamic-programming-lecture-egm-stochastic#id-key-takeaway","position":78},{"hierarchy":{"lvl1":"Dynamic Programming","lvl3":"ðŸ§  Key Takeaway","lvl2":"ðŸ“˜ Conditions for a Contraction Mapping"},"content":"A function T is a contraction mapping if it:\n\nActs on a complete metric space,\n\nMaps the space into itself, and\n\nShrinks distances by a constant factor \\beta < 1.\n\nThen, the Banach Fixed Point Theorem guarantees:\n\nA unique fixed point x^*,\n\nConvergence of iteration x_{n+1} = T(x_n) from any start x_0,\n\nGeometric rate of convergence: d(x_n, x^*) \\le \\beta^n d(x_0, x^*).\n\n","type":"content","url":"/dynamic-programming-lecture-egm-stochastic#id-key-takeaway","position":79},{"hierarchy":{"lvl1":"Dynamic Programming","lvl3":"Numerical methods â€” overview","lvl2":"ðŸ“˜ Conditions for a Contraction Mapping"},"type":"lvl3","url":"/dynamic-programming-lecture-egm-stochastic#numerical-methods-overview","position":80},{"hierarchy":{"lvl1":"Dynamic Programming","lvl3":"Numerical methods â€” overview","lvl2":"ðŸ“˜ Conditions for a Contraction Mapping"},"content":"Common approaches:\n\nValue Function Iteration (VFI) â€” robust but can be slow when discount factor is close to 1 or state grid is large.\n\nPolicy Iteration / Howardâ€™s improvement â€” often faster; requires solving linear systems (finite state).\n\nEndogenous Grid Method (EGM) â€” very fast for single-state consumptionâ€“savings problems where Euler equation is invertible.\n\nCollocation / projection methods â€” approximate value function with basis functions; powerful for smooth problems in continuous state spaces.\n\n","type":"content","url":"/dynamic-programming-lecture-egm-stochastic#numerical-methods-overview","position":81},{"hierarchy":{"lvl1":"Dynamic Programming","lvl4":"Numerical example: VFI (Python)","lvl3":"Numerical methods â€” overview","lvl2":"ðŸ“˜ Conditions for a Contraction Mapping"},"type":"lvl4","url":"/dynamic-programming-lecture-egm-stochastic#numerical-example-vfi-python","position":82},{"hierarchy":{"lvl1":"Dynamic Programming","lvl4":"Numerical example: VFI (Python)","lvl3":"Numerical methods â€” overview","lvl2":"ðŸ“˜ Conditions for a Contraction Mapping"},"content":"The cell below contains a runnable implementation of Value Function Iteration for a small CRRA consumptionâ€“savings model with two income states. Run it to compute the value functions and the policy function (next-period assets) and plot the results.\n\n# VFI implementation for a simple consumption-savings problem with discrete income (runnable)\n# This version has extra inline comments explaining shapes, broadcasting, and algorithmic steps.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# -------------------------\n# Model parameters\n# -------------------------\n# Discount factor: how much agents value the future vs present\nbeta = 0.96\n\n# Interest rate on assets (gross return = 1 + r)\nr = 0.04\n\n# CRRA risk aversion parameter (gamma = 1 is log utility; here we use 2 as a common example)\ngamma = 2.0\n\n# Asset grid: we discretize assets between a_min and a_max with Na points\na_min, a_max, Na = 0.0, 20.0, 200\na_grid = np.linspace(a_min, a_max, Na)  # shape (Na,)\n\n# -------------------------\n# Income process (discrete)\n# -------------------------\n# Two income states for simplicity: low and high\ny_vals = np.array([0.5, 1.5])           # shape (Ny,) where Ny = 2\n\n# Transition matrix P: P[iy, jy] = Prob(y' = jy | current y = iy)\n# Rows should sum to 1. Here we use a simple persistence structure.\nP = np.array([[0.9, 0.1],\n              [0.1, 0.9]])              # shape (Ny, Ny)\n\n# -------------------------\n# Utility function\n# -------------------------\ndef utility(c):\n    \"\"\"CRRA utility with safeguard to avoid taking powers/log of nonpositive numbers.\n    This function accepts array input via numpy broadcasting and returns an array of same shape.\n    \"\"\"\n    c_safe = np.maximum(c, 1e-12)  # prevent nonpositive consumption\n    if gamma == 1.0:\n        return np.log(c_safe)\n    else:\n        return (c_safe ** (1.0 - gamma)) / (1.0 - gamma)\n\n# -------------------------\n# Value function initialization\n# -------------------------\n# V[a_index, y_index] stores the value of being at assets a_grid[a_index] and income y_vals[y_index]\nV = np.zeros((Na, len(y_vals)))  # initial guess: zeros\n\n# Convergence settings\ntol = 1e-6\nmax_iter = 2000\n\n# -------------------------\n# Value Function Iteration (VFI)\n# -------------------------\n# The main loop performs Bellman updates until V converges.\n# At each iteration and for each current income state 'iy' we:\n# 1. For each current asset a (index ia), consider all candidate next-period assets a' (indexed by ia_prime).\n# 2. Compute feasible consumption c = (1+r)*a + y - a' for each pair (a, a').\n#    This produces a matrix of shape (Na, Na) where rows correspond to current a and columns to a'.\n# 3. Compute one-period utility U(c) for the entire (Na, Na) matrix.\n# 4. Compute the expected continuation value for each candidate a' as:\n#       E[V(a', y')] = sum_{y'} P[iy, y'] * V[a_prime_index, y']\n#    This yields a vector of length Na (indexed by a').\n# 5. Add the discounted continuation value to the one-period utility (broadcasted over rows).\n# 6. Maximize over a' (columns) to update V_new[a, iy].\n#\n# Vectorization notes:\n# - We build the consumption matrix c with broadcasting: a_grid[:, None] (shape (Na,1)) and a_grid[None, :] (shape (1,Na)).\n# - The continuation value cont is computed as an expected value across next-period income states using matrix multiply.\n# - cont has shape (Na,) and is added to every row of U (hence cont[None, :]).\n\nfor it in range(max_iter):\n    V_new = np.empty_like(V)  # placeholder for updated value function\n\n    # Loop over current income states (small dimension Ny = 2 here â€” looping is fine)\n    for iy, y in enumerate(y_vals):\n        # Build candidate consumption matrix:\n        # For current assets along rows (shape (Na,1)) and a' along columns (shape (1,Na))\n        # c[ia, ia_prime] = (1+r)*a_grid[ia] + y - a_grid[ia_prime]\n        c = (1.0 + r) * a_grid[:, None] + y - a_grid[None, :]\n        c = np.maximum(c, 1e-12)  # enforce nonnegativity for numerical stability\n\n        # One-period utility for every (a, a') pair: shape (Na, Na)\n        U = utility(c)\n\n        # Expected continuation value for each candidate a' (vector of length Na):\n        # P[iy, :] is the row of transition probabilities from current income state iy\n        # V.T has shape (Ny, Na) after transpose, so (P[iy, :] @ V.T) yields a vector of length Na\n        # Multiply by beta to discount future utility.\n        cont = beta * (P[iy, :] @ V.T).T  # shape (Na,)\n\n        # Right-hand side: one-period utility + discounted expected continuation value\n        # We add cont[None, :] (shape (1, Na)) to U (shape (Na, Na)); broadcasting applies across rows.\n        RHS = U + cont[None, :]\n\n        # Maximize over columns (a' choices) for each row (current a)\n        # axis=1 corresponds to maximizing across candidate a' for each current a\n        V_new[:, iy] = np.max(RHS, axis=1)\n\n    # Compute sup-norm difference for convergence check\n    diff = np.max(np.abs(V_new - V))\n    V[:] = V_new  # update value function\n\n    if diff < tol:\n        print(f'Converged after {it+1} iterations, diff={diff:.2e}')\n        break\nelse:\n    print('VFI did not converge within max_iter')\n\n# -------------------------\n# Recovering the policy function\n# -------------------------\n# After convergence, recover the argmax (policy) that attains the maximum for each (a, y).\n# policy_idx[a_index, y_index] = index of a' chosen (an integer index into a_grid)\npolicy_idx = np.empty_like(V, dtype=int)\n\nfor iy, y in enumerate(y_vals):\n    # Recompute the same RHS components to obtain argmax (this repeats some computation;\n    # in production code you might store argmax during the VFI loop to avoid recomputing)\n    c = (1.0 + r) * a_grid[:, None] + y - a_grid[None, :]\n    c = np.maximum(c, 1e-12)\n    U = utility(c)\n    cont = beta * (P[iy, :] @ V.T).T\n    RHS = U + cont[None, :]\n    policy_idx[:, iy] = np.argmax(RHS, axis=1)   # index of optimal a' for each current a\n\n# Convert index to actual asset choices a' (policy in levels)\npolicy_a_prime = a_grid[policy_idx]  # shape (Na, Ny)\n\n# -------------------------\n# Plots: value functions and policy functions\n# -------------------------\nfig, axes = plt.subplots(1, 2, figsize=(10, 4))\n\n# Value functions for the two income states\naxes[0].plot(a_grid, V[:, 0], label=f'y={y_vals[0]}')\naxes[0].plot(a_grid, V[:, 1], label=f'y={y_vals[1]}')\naxes[0].set_title('Value function V(a,y)')\naxes[0].set_xlabel('Assets a')\naxes[0].set_ylabel('Value V')\naxes[0].legend()\n\n# Policy: a' choice as function of current assets for each income state\naxes[1].plot(a_grid, policy_a_prime[:, 0], label=f'y={y_vals[0]}')\naxes[1].plot(a_grid, policy_a_prime[:, 1], label=f'y={y_vals[1]}')\naxes[1].set_title(\"Policy: a' (next assets)\")\naxes[1].set_xlabel('Assets a')\naxes[1].set_ylabel(\"Chosen a'\")\naxes[1].legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n","type":"content","url":"/dynamic-programming-lecture-egm-stochastic#numerical-example-vfi-python","position":83},{"hierarchy":{"lvl1":"Dynamic Programming","lvl3":"Endogenous Grid Method (EGM) â€” intuition & sketch","lvl2":"ðŸ“˜ Conditions for a Contraction Mapping"},"type":"lvl3","url":"/dynamic-programming-lecture-egm-stochastic#endogenous-grid-method-egm-intuition-sketch","position":84},{"hierarchy":{"lvl1":"Dynamic Programming","lvl3":"Endogenous Grid Method (EGM) â€” intuition & sketch","lvl2":"ðŸ“˜ Conditions for a Contraction Mapping"},"content":"EGM is useful when the problemâ€™s Euler equation can be inverted easily (e.g., CRRA utility and a single continuous state like assets).Key idea:\n\nWork on grid for next-period assets a'.\n\nCompute expected marginal utility of consumption tomorrow on that grid.\n\nInvert the Euler equation to get current consumption c at the implied current asset a.\n\nThis produces (a, c(a)) pairs that are interpolated back onto the original asset grid.\n\nEGM avoids root finding at each a and is often substantially faster than naive VFI for single-state problems.\n\n","type":"content","url":"/dynamic-programming-lecture-egm-stochastic#endogenous-grid-method-egm-intuition-sketch","position":85},{"hierarchy":{"lvl1":"Dynamic Programming","lvl3":"Exercises (in-class / take-home)","lvl2":"ðŸ“˜ Conditions for a Contraction Mapping"},"type":"lvl3","url":"/dynamic-programming-lecture-egm-stochastic#exercises-in-class-take-home","position":86},{"hierarchy":{"lvl1":"Dynamic Programming","lvl3":"Exercises (in-class / take-home)","lvl2":"ðŸ“˜ Conditions for a Contraction Mapping"},"content":"Deterministic growth model. Implement VFI for the deterministic growth model with log utility and Cobbâ€“Douglas production f(k)=k^\\alpha. Compute policy and value functions.\n\nTwo-state income. Modify the VFI above to increase Na and explore how solution time scales. Try different gamma values.\n\nEGM practice. Implement the EGM for the consumptionâ€“savings model (single-state stochastic income if you like). Compare runtime vs VFI for a moderate grid.\n\nPolicy iteration. For a finite-state discretized model, implement policy iteration and compare number of iterations to VFI for high beta (e.g., beta=0.99).\n\n","type":"content","url":"/dynamic-programming-lecture-egm-stochastic#exercises-in-class-take-home","position":87},{"hierarchy":{"lvl1":"Dynamic Programming","lvl3":"Suggested readings","lvl2":"ðŸ“˜ Conditions for a Contraction Mapping"},"type":"lvl3","url":"/dynamic-programming-lecture-egm-stochastic#suggested-readings","position":88},{"hierarchy":{"lvl1":"Dynamic Programming","lvl3":"Suggested readings","lvl2":"ðŸ“˜ Conditions for a Contraction Mapping"},"content":"Stokey, Lucas & Prescott (1989), Recursive Methods in Economic Dynamics.\n\nJudd (1998), Numerical Methods in Economics.\n\nLjungqvist & Sargent, Recursive Macroeconomic Theory.\n\nCarroll (2006), â€œThe method of endogenous gridpoints for solving dynamic stochastic optimization problemsâ€.\n\n","type":"content","url":"/dynamic-programming-lecture-egm-stochastic#suggested-readings","position":89},{"hierarchy":{"lvl1":"Dynamic Programming","lvl3":"Endogenous Grid Method (EGM) â€” commented implementation and runtime comparison","lvl2":"ðŸ“˜ Conditions for a Contraction Mapping"},"type":"lvl3","url":"/dynamic-programming-lecture-egm-stochastic#endogenous-grid-method-egm-commented-implementation-and-runtime-comparison","position":90},{"hierarchy":{"lvl1":"Dynamic Programming","lvl3":"Endogenous Grid Method (EGM) â€” commented implementation and runtime comparison","lvl2":"ðŸ“˜ Conditions for a Contraction Mapping"},"content":"Below we provide:\n\nA clear, commented implementation of the Endogenous Grid Method (EGM) for a single-state\nconsumptionâ€“savings model (CRRA utility, deterministic labor income).\n\nA comparable VFI implementation for the same deterministic model (so the two methods solve\nthe same problem).\n\nA runtime comparison across several asset-grid sizes to illustrate the computational advantages\nof EGM in this canonical setting.\n\nNotes:\n\nFor clarity we implement the deterministic-income version of the model (no stochastic shocks).\n\nThe EGM algorithm implemented here follows the common textbook recipe:\n\nStart with an initial guess for the consumption policy on the asset grid.\n\nGiven the previous period consumption function, compute marginal utility next period at each aâ€™.\n\nInvert Euler to get current consumption at the implied current asset (endogenous grid).\n\nInterpolate the resulting (a_implied, c_current) pairs back to the original a_grid.\n\nRepeat until the consumption policy converges.\n\n# EGM vs VFI: implementations and timing comparison\nimport numpy as np\nimport time\nimport matplotlib.pyplot as plt\nfrom scipy import interpolate\n\n# -------------------------\n# Model primitives (deterministic income)\n# -------------------------\nbeta = 0.96       # discount factor\nr = 0.04          # interest rate\ngamma = 2.0       # CRRA risk aversion (gamma=1 is log utility)\ny = 1.0           # deterministic income each period\na_min = 0.0       # borrowing constraint (natural boundary)\n# We'll vary a_max and Na (grid size) below for timing comparison.\n\n# Utility and marginal utility functions\ndef u(c):\n    c_safe = np.maximum(c, 1e-12)\n    if gamma == 1.0:\n        return np.log(c_safe)\n    else:\n        return (c_safe ** (1.0 - gamma)) / (1.0 - gamma)\n\ndef mu(c):\n    # marginal utility u'(c) = c^{-gamma} for CRRA\n    c_safe = np.maximum(c, 1e-12)\n    return c_safe ** (-gamma)\n\ndef mu_inv(mu_val):\n    # inverse marginal utility: given marginal utility, return c\n    # For CRRA: mu = c^{-gamma} => c = mu^{-1/gamma}\n    return mu_val ** (-1.0 / gamma)\n\n# -------------------------\n# VFI implementation for deterministic model (function)\n# -------------------------\ndef solve_vfi_det(a_grid, beta=beta, r=r, y=y, tol=1e-6, max_iter=2000):\n    \"\"\"Solve deterministic consumption-savings via naive VFI on given asset grid.\n    Returns: consumption policy c_policy (shape Na,), value function V (Na,), and timing info.\n    \"\"\"\n    Na = len(a_grid)\n    V = np.zeros(Na)                # initial guess for value function\n    c_policy = np.zeros(Na)         # to store policy in levels\n    # Precompute resource (cash-on-hand) for state a and candidate a'\n    # We'll vectorize across a (rows) and a' (cols)\n    A = a_grid[:, None]             # shape (Na,1)\n    Aprime = a_grid[None, :]        # shape (1,Na)\n\n    start = time.perf_counter()\n    for it in range(max_iter):\n        V_new = np.empty_like(V)\n        # compute RHS for all (a, a') pairs\n        cons = (1.0 + r) * A + y - Aprime   # shape (Na, Na)\n        cons = np.maximum(cons, 1e-12)\n        U = u(cons)                         # shape (Na, Na)\n        # continuation value is V evaluated at a' (vector length Na), broadcast across rows\n        cont = beta * V[None, :]            # shape (1, Na)\n        RHS = U + cont                      # shape (Na, Na)\n        V_new = np.max(RHS, axis=1)        # max over columns (a') for each row (current a)\n        # Check convergence\n        diff = np.max(np.abs(V_new - V))\n        V[:] = V_new\n        if diff < tol:\n            break\n    end = time.perf_counter()\n    # Recover policy (argmax)\n    cons = (1.0 + r) * A + y - Aprime\n    cons = np.maximum(cons, 1e-12)\n    U = u(cons)\n    cont = beta * V[None, :]\n    RHS = U + cont\n    idx = np.argmax(RHS, axis=1)\n    c_policy = cons[np.arange(Na), idx]\n    return c_policy, V, end - start, it+1\n\n# -------------------------\n# EGM implementation for deterministic model (function)\n# -------------------------\ndef solve_egm_det(a_grid, beta=beta, r=r, y=y, tol=1e-6, max_iter=2000):\n    \"\"\"Solve deterministic consumption-savings via EGM with safe interpolation.\"\"\"\n    Na = len(a_grid)\n    # initial guess: consume half of cash-on-hand\n    c_policy = 0.5 * ((1.0 + r) * a_grid + y)\n    c_policy = np.maximum(c_policy, 1e-12)\n\n    start = time.perf_counter()\n    for it in range(max_iter):\n        # 1) next-period consumption on a' grid\n        c_next = c_policy.copy()\n        # 2) next-period marginal utility\n        muc_next = mu(c_next)\n        # 3) invert Euler: u'(c) = beta(1+r)u'(c')\n        factor = beta * (1.0 + r) * muc_next\n        # guard against numerical under/overflow\n        factor = np.maximum(factor, 1e-300)\n        c_current_at_a_prime = mu_inv(factor)\n\n        # 4) implied current asset that leads to (c_current, a')\n        a_implied = (c_current_at_a_prime + a_grid - y) / (1.0 + r)\n\n        # 5) borrowing constraint handling: if a_implied < a_min, the correct solution is a=a_min\n        mask_below = a_implied < a_min\n        if np.any(mask_below):\n            a_implied[mask_below] = a_min\n            # at the constraint the optimal a' is a_min; consumption there is c = (1+r)a_min + y - a'\n            # since we are sitting at a=a_min, set a' = a_min for the constraint point\n            # i.e., c = y + r*a_min - a_min = y + (r-1)*a_min; with a_min=0 this is y\n            c_current_at_a_prime[mask_below] = (1.0 + r) * a_min + y - a_min\n\n        # 6) sort by a_implied and collapse duplicate x's (take max c for each unique a)\n        sort_idx = np.argsort(a_implied)\n        x = a_implied[sort_idx]\n        y_c = c_current_at_a_prime[sort_idx]\n\n        # collapse duplicates robustly\n        unique_x = []\n        unique_c = []\n        i = 0\n        n = x.size\n        while i < n:\n            j = i + 1\n            while j < n and x[j] == x[i]:\n                j += 1\n            unique_x.append(x[i])\n            # at duplicated a (notably a_min), keep the largest feasible consumption\n            unique_c.append(np.max(y_c[i:j]))\n            i = j\n\n        x = np.asarray(unique_x)\n        y_c = np.asarray(unique_c)\n\n        # ensure we have the constraint anchor explicitly (use correct c at a_min)\n        if x[0] > a_min:\n            x = np.insert(x, 0, a_min)\n            y_c = np.insert(y_c, 0, (1.0 + r) * a_min + y - a_min)\n\n        # if any tiny non-monotonicity remains, enforce strictly increasing x by jittering eps\n        # (rarely needed, but keeps interp1d happy)\n        eps = 0.0\n        for k in range(1, x.size):\n            if x[k] <= x[k-1]:\n                eps = max(eps, 1e-12 * (1.0 + abs(x[k-1])))\n                x[k] = x[k-1] + eps\n\n        # 7) interpolate back to the original grid\n        interp = interpolate.interp1d(x, y_c, kind='linear', bounds_error=False, fill_value='extrapolate')\n        c_new = interp(a_grid)\n        c_new = np.maximum(c_new, 1e-12)\n\n        # 8) convergence\n        diff = np.max(np.abs(c_new - c_policy))\n        c_policy[:] = c_new\n        if diff < tol:\n            break\n\n    end = time.perf_counter()\n    return c_policy, end - start, it + 1\n\n# -------------------------\n# Timing comparison across grid sizes\n# -------------------------\ngrid_sizes = [100, 200, 400, 800]  # adjust depending on runtime tolerance in this environment\nvfi_times = []\negm_times = []\nvfi_iters = []\negm_iters = []\n\nfor Na in grid_sizes:\n    a_max = 50.0\n    a_grid = np.linspace(a_min, a_max, Na)\n\n    # Time VFI (deterministic)\n    c_vfi, V_vfi, t_vfi, it_vfi = solve_vfi_det(a_grid)\n    vfi_times.append(t_vfi)\n    vfi_iters.append(it_vfi)\n\n    # Time EGM\n    c_egm, t_egm, it_egm = solve_egm_det(a_grid)\n    egm_times.append(t_egm)\n    egm_iters.append(it_egm)\n\n    print(f\"Na={Na}: VFI time={t_vfi:.4f}s (iters={it_vfi}), EGM time={t_egm:.4f}s (iters={it_egm})\")\n\n# -------------------------\n# Plot timing results\n# -------------------------\nplt.figure(figsize=(6,4))\nplt.plot(grid_sizes, vfi_times, marker='o', label='VFI (deterministic)')\nplt.plot(grid_sizes, egm_times, marker='o', label='EGM')\nplt.xlabel('Number of asset grid points (Na)')\nplt.ylabel('Compute time (seconds)')\nplt.title('Runtime comparison: VFI vs EGM (deterministic model)')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n# -------------------------\n# Show policy functions for the finest grid\n# -------------------------\nNa = grid_sizes[-1]\na_grid = np.linspace(a_min, 50.0, Na)\nc_vfi, V_vfi, t_vfi, it_vfi = solve_vfi_det(a_grid)\nc_egm, t_egm, it_egm = solve_egm_det(a_grid)\n\nplt.figure(figsize=(8,4))\nplt.plot(a_grid, c_vfi, label='VFI consumption policy')\nplt.plot(a_grid, c_egm, label='EGM consumption policy', linestyle='--')\nplt.xlabel('Assets a')\nplt.ylabel('Consumption c(a)')\nplt.title(f'Policy functions (Na={Na}) â€” VFI vs EGM')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n","type":"content","url":"/dynamic-programming-lecture-egm-stochastic#endogenous-grid-method-egm-commented-implementation-and-runtime-comparison","position":91},{"hierarchy":{"lvl1":"Dynamic Programming","lvl4":"Notes on the comparison","lvl3":"Endogenous Grid Method (EGM) â€” commented implementation and runtime comparison","lvl2":"ðŸ“˜ Conditions for a Contraction Mapping"},"type":"lvl4","url":"/dynamic-programming-lecture-egm-stochastic#notes-on-the-comparison","position":92},{"hierarchy":{"lvl1":"Dynamic Programming","lvl4":"Notes on the comparison","lvl3":"Endogenous Grid Method (EGM) â€” commented implementation and runtime comparison","lvl2":"ðŸ“˜ Conditions for a Contraction Mapping"},"content":"The EGM method here solves the same deterministic problem more efficiently because it avoids maximizing over aâ€™ at each grid point; instead it constructs a mapping from aâ€™ to implied a and inverts it via interpolation.\n\nFor stochastic problems with Markov income, EGM can be extended but requires computing expected marginal utilities (integration over shocks), which slightly complicates the implementation â€” the performance advantages generally remain for single-state control problems.\n\nThe runtime numbers printed above are illustrative and will depend on the machine and environment; they show how EGM scales more gently with grid size compared to naive VFI.\n\n","type":"content","url":"/dynamic-programming-lecture-egm-stochastic#notes-on-the-comparison","position":93},{"hierarchy":{"lvl1":"Dynamic Programming","lvl3":"EGM extended to discrete Markov income (stochastic EGM)","lvl2":"ðŸ“˜ Conditions for a Contraction Mapping"},"type":"lvl3","url":"/dynamic-programming-lecture-egm-stochastic#egm-extended-to-discrete-markov-income-stochastic-egm","position":94},{"hierarchy":{"lvl1":"Dynamic Programming","lvl3":"EGM extended to discrete Markov income (stochastic EGM)","lvl2":"ðŸ“˜ Conditions for a Contraction Mapping"},"content":"This section implements the Endogenous Grid Method (EGM) for a consumptionâ€“savings\nproblem with a discrete Markov income process. The key difference from the deterministic\nEGM is that the expected marginal utility next period must average over the possible income\nstates next period using the transition matrix.\n\nWe implement solve_egm_stochastic which iterates on the consumption policy\nc(a, y) defined on a grid of assets and on the discrete income states.\nThe algorithm (high level) for each current income state y_i:\n\nFor each candidate next asset aâ€™ (grid point), collect c_next(aâ€™, yâ€™) across all possible yâ€™ (from previous iterate).\n\nCompute expected marginal utility: muc_next(aâ€™) = sum_{yâ€™} P[y_i, yâ€™] * uâ€™( c_next(aâ€™, yâ€™) ).\n\nInvert Euler to get current consumption c(a_implied, y_i) at each aâ€™ via c = (beta*(1+r)*muc_next)^{-1/gamma}.\n\nCompute implied current asset a_implied = (c + aâ€™ - y_i) / (1+r).\n\nHandle points where a_implied < borrowing constraint and interpolate to map back to the original grid.\n\nThe function returns the converged consumption policy c_policy (shape Na x Ny), timing, and iterations.\n\nfrom IPython.display import HTML, display\n\ndisplay(HTML(\"\"\"\n<style>\n/* Expand notebook width */\n.container { \n    width: 100% !important;\n}\n\n/* Disable output scrolling */\n.output_scroll {\n    height: auto !important;\n    max-height: none !important;\n    overflow-y: visible !important;\n}\n\n/* Also expand output area width */\n.output_wrapper, .output {\n    overflow-x: visible !important;\n}\n</style>\n\"\"\"))\n\n\n\n\n# EGM for stochastic income (discrete Markov) + demo run\nimport numpy as np\nimport time\nimport matplotlib.pyplot as plt\nfrom scipy import interpolate\n\n# Model primitives (shared)\nbeta = 0.96\nr = 0.04\ngamma = 2.0\na_min = 0.0\n\ndef mu(c):\n    c_safe = np.maximum(c, 1e-12)\n    return c_safe ** (-gamma)\n\ndef mu_inv(mu_val):\n    return mu_val ** (-1.0 / gamma)\n\n# -------------------------\n# Stochastic EGM solver\n# -------------------------\ndef solve_egm_stochastic(a_grid, y_vals, P, beta=beta, r=r, tol=1e-6, max_iter=2000):\n    \"\"\"Endogenous Grid Method for a model with discrete Markov income.\n    Inputs:\n      - a_grid: 1D array of asset grid points (Na,)\n      - y_vals: 1D array of income states (Ny,)\n      - P: transition matrix shape (Ny, Ny) with rows summing to 1\n    Returns:\n      - c_policy: consumption policy array shape (Na, Ny) mapping (a, y) -> c\n      - elapsed_time: seconds\n      - n_iter: iterations taken\n    Notes:\n      - We iterate on the consumption policy c(a, y).\n      - For each current income state i and for each a' in the grid we compute expected\n        marginal utility using P[i, :], invert Euler, get implied a, then interpolate.\n    \"\"\"\n    Na = len(a_grid)\n    Ny = len(y_vals)\n\n    # Initial guess: consume a fraction of cash-on-hand for each income state\n    # cash on hand = (1+r)*a + y, choose to consume half of it initially\n    coh = (1.0 + r) * a_grid[:, None] + y_vals[None, :]   # shape (Na, Ny)\n    c_policy = 0.5 * coh                                   # initial c(a,y), shape (Na, Ny)\n    c_policy = np.maximum(c_policy, 1e-12)\n\n    start = time.perf_counter()\n    for it in range(max_iter):\n        c_new = np.empty_like(c_policy)\n        # For each current income state y_i compute implied a and c from a' grid\n        for iy, y in enumerate(y_vals):\n            # For each candidate a' (index j), we need c_next at (a'=a_grid[j], every y')\n            # Extract c_next(a', y') as a vector of length Ny for each a' -- that's c_policy[j, :].\n            # We'll loop over a' index vectorized with array ops.\n            # c_next_matrix has shape (Na, Ny) where row j corresponds to a'=a_grid[j] across y'\n            c_next_matrix = c_policy.copy()  # shape (Na, Ny): rows are a' indices\n\n            # Compute marginal utility at next period for each (a', y') -> shape (Na, Ny)\n            muc_next = mu(c_next_matrix)     # shape (Na, Ny)\n\n            # Compute expected marginal utility conditional on current income state iy:\n            # For each a' (row), take inner product with P[iy, :] over columns (y' dimension)\n            # This yields a vector of length Na: muc_exp[j] = sum_{y'} P[iy, y'] * muc_next[j, y']\n            muc_exp = muc_next @ P[iy, :].T   # shape (Na,)   (matrix-vector multiplication)\n\n            # Invert Euler condition for each a' to get current consumption associated with that a'\n            factor = beta * (1.0 + r) * muc_exp\n            c_current_at_aprime = mu_inv(factor)   # shape (Na,)\n\n            # Get implied current asset for each a' using budget identity:\n            # a = (c + a' - y) / (1+r)\n            a_implied = (c_current_at_aprime + a_grid - y) / (1.0 + r)  # shape (Na,)\n\n            # Handle borrowing constraint: where a_implied < a_min, set a_implied = a_min and recompute c\n            mask = a_implied < a_min\n            if np.any(mask):\n                a_implied[mask] = a_min\n                # recompute c for these a' from budget: c = (1+r)*a_min + y - a'\n                c_current_at_aprime[mask] = (1.0 + r) * a_min + y - a_grid[mask]\n\n            # Now we have pairs (a_implied, c_current_at_aprime) of length Na.\n            # Sort by a_implied (necessary for monotone interpolation)\n            sort_idx = np.argsort(a_implied)\n            a_sorted = a_implied[sort_idx]\n            c_sorted = c_current_at_aprime[sort_idx]\n\n            # Remove duplicate a's to avoid zero denominators in slope calculation\n            a_unique, unique_idx = np.unique(a_sorted, return_index=True)\n            c_unique = c_sorted[unique_idx]\n\n            # Interpolate onto original a_grid to get c(a_grid, y_i)\n            interp = interpolate.interp1d(a_unique, c_unique, kind='linear',\n                                          bounds_error=False, fill_value='extrapolate')\n            c_on_grid = interp(a_grid)\n            c_on_grid = np.maximum(c_on_grid, 1e-12)\n            c_new[:, iy] = c_on_grid\n\n        # Convergence check across all (a,y)\n        diff = np.max(np.abs(c_new - c_policy))\n        c_policy[:] = c_new\n        if diff < tol:\n            break\n\n    elapsed = time.perf_counter() - start\n    return c_policy, elapsed, it+1\n\n# -------------------------\n# Demo run: small Markov income process\n# -------------------------\ny_vals = np.array([0.5, 1.5])   # low and high income\nP = np.array([[0.9, 0.1],\n              [0.1, 0.9]])      # transition matrix (rows sum to 1)\n\nNa = 400\na_max = 50.0\na_grid = np.linspace(a_min, a_max, Na)\n\nc_stoch_egm, t_stoch_egm, it_stoch_egm = solve_egm_stochastic(a_grid, y_vals, P)\nprint(f'Stochastic EGM converged in {it_stoch_egm} iters, time {t_stoch_egm:.4f}s')\n\n# Plot policy functions for each income state\nplt.figure(figsize=(8,4))\nplt.plot(a_grid, c_stoch_egm[:,0], label=f'EGM c(a, y_low={y_vals[0]})')\nplt.plot(a_grid, c_stoch_egm[:,1], label=f'EGM c(a, y_high={y_vals[1]})', linestyle='--')\nplt.xlabel('Assets a')\nplt.ylabel('Consumption c(a,y)')\nplt.title('Stochastic EGM: Consumption policy by income state')\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n","type":"content","url":"/dynamic-programming-lecture-egm-stochastic#egm-extended-to-discrete-markov-income-stochastic-egm","position":95},{"hierarchy":{"lvl1":"Dynamic Programming","lvl4":"Notes","lvl3":"EGM extended to discrete Markov income (stochastic EGM)","lvl2":"ðŸ“˜ Conditions for a Contraction Mapping"},"type":"lvl4","url":"/dynamic-programming-lecture-egm-stochastic#notes","position":96},{"hierarchy":{"lvl1":"Dynamic Programming","lvl4":"Notes","lvl3":"EGM extended to discrete Markov income (stochastic EGM)","lvl2":"ðŸ“˜ Conditions for a Contraction Mapping"},"content":"This stochastic EGM iterates on the consumption policy across both assets and income states.\n\nPerformance depends on Ny (number of income states) and Na (asset grid size). Expect runtime to scale roughly linearly in Ny for fixed Na.\n\nFor smoother interpolation or better handling of kinks near borrowing constraints, one can use piecewise-linear splines or monotone cubic interpolation, but linear interpolation is robust and simple.\n\n## 8. (Optional) Minimal Python illustration: value iteration for a small MDP\n\n# simple value iteration for a small finite MDP\nimport numpy as np\n\n# example: 2 states, 2 actions\nP = {\n  0: {0: [(1.0,0)], 1: [(1.0,1)]},   # action 0 keeps state 0, action 1 moves to state 1\n  1: {0: [(1.0,1)], 1: [(1.0,1)]}    # absorbing state 1\n}\nR = {\n  (0,0): 1.0, (0,1): 2.0,\n  (1,0): 0.0, (1,1): 0.0\n}\nbeta = 0.9\nV = np.zeros(2)\n\nfor it in range(100):\n    V_new = V.copy()\n    for s in [0,1]:\n        vals = []\n        for a in [0,1]:\n            expV = sum(p * V[s2] for (p,s2) in P[s][a])\n            vals.append(R[(s,a)] + beta*expV)\n        V_new[s] = max(vals)\n    if np.max(np.abs(V_new - V)) < 1e-8:\n        break\n    V = V_new\nprint(\"Value function:\", V)\n\n","type":"content","url":"/dynamic-programming-lecture-egm-stochastic#notes","position":97},{"hierarchy":{"lvl1":""},"type":"lvl1","url":"/hp1","position":0},{"hierarchy":{"lvl1":""},"content":"# The HP Filter\n\n## Learning objectives\n- Understand trendâ€“cycle decomposition\n- Interpret the smoothing parameter $\\lambda$\n\nSmoothing time series data is useful in many economic situations. The main idea is to try to separate a \"trend\" from a \"cycle.\" The smoothed series should not differ too much from the actual data. This is done through a choice of parameters in the filter. \n\n## Setup\n Suppose we have $T$ observations on the log of some time series $y_{t}$ for $t=1,2, \\ldots , T$, where $y_{t}$ consists of a trend term, $\\tau_{t}$, and a cyclical component, $c_{t}$, so that $y_{t} = \\tau_{t} + c_{t}$. \n\nThe HP filter finds $\\{\\tau_{t}\\}$ that solves\n\n$$ \n\\min_{\\tau} \\Big(\\sum_{t=1}^{T} (c)^2 + \\lambda \\sum_{t=1}^{T} [(\\tau_{t}-\\tau_{t-1})-(\\tau_{t-1}-\\tau_{t-2})]^2  \\Big), \n$$\nor, rewriting\n$$ \n \\min_{\\tau} \\Big(\\sum_{t=1}^{T} (y_{t}-\\tau_{t})^2 + \\lambda \\sum_{t=1}^{T} [(\\tau_{t}-\\tau_{t-1})-(\\tau_{t-1}-\\tau_{t-2})]^2  \\Big),\n$$\n\n##\n\nwhere $\\lambda$ is the ``smoothness penalty.'' Note that as $\\lambda \\rightarrow 0$, we just have the series, $y_{t}$, itself and $\\lambda \\rightarrow \\infty$ is just a regression on a linear trend (second difference is $0$). Here is a Python implementation:\n\nimport numpy as np\nimport pandas as pd\nimport pandas_datareader as pdr\nimport datetime\nfrom statsmodels.tsa.filters.hp_filter import hpfilter\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nfrom cycler import cycler\nfrom tabulate import tabulate\nfrom matplotlib.dates import DateFormatter\nfrom pandas.plotting import register_matplotlib_converters\nregister_matplotlib_converters\nimport matplotlib.ticker as ticker\n###from statsmodels.tsa.x13 import x13_arima_analysis\nimport sys\n### Some libraries for web scraping (BLS revisions)\nimport requests\nfrom bs4 import BeautifulSoup\nimport time\n\nstart_time = time.time()\n\npd.set_option('display.max_rows', None)\n\nmy_colors = [\"#00688b\",\n             \"#cd3333\",\n             \"#6c8b3d\", \n             \"cornflowerblue\",\n             \"#cd6600\",\n             \"#8b2323\",\n             \"#5d478b\",\n             \"red\"]\nplt.rcParams['axes.prop_cycle'] = cycler(color = my_colors)\nplt.rcParams['axes.spines.right'] = False\nplt.rcParams['axes.spines.top'] = False\nplt.rcParams['axes.xmargin'] = 0\n#plt.rcParams['axes.ymargin'] = 0.0\nplt.rcParams[\"figure.figsize\"] = (10.5,6.5)\nplt.rcParams['font.family'] = 'sans-serif'\nplt.rcParams['font.size'] = 14\nplt.rcParams['legend.fontsize'] = 'medium'\nplt.rcParams['legend.frameon'] = False\nplt.rcParams['legend.framealpha'] = None\nplt.rcParams[\"legend.loc\"] = 'best' \nplt.rcParams['axes.titlesize'] = 'xx-large'\nplt.rcParams['axes.titlecolor'] = '#3333B3FF'\nplt.rcParams['lines.linewidth'] = 3\n\nplt.rcParams['figure.subplot.left'] = 0\nplt.rcParams['figure.subplot.bottom'] = 0\nplt.rcParams['figure.subplot.right'] = 1\nplt.rcParams['figure.subplot.top'] = 1\n\ndef crosscorr(datax, datay, lag=0):\n   return datax.corr(datay.shift(lag))\n\ndef NBER(start_date):\n    ax2 = ax.twinx()\n    Recessions = monthly['recessiondates'][monthly.index >= start_date]\n    ax2.fill_between(Recessions.index,\n                     Recessions,\n                     step=\"pre\",\n                     color=\"gray\",\n                     alpha=0.2)\n    ax2.get_yaxis().set_visible(False)\n    return ax2\n\ndef simpleaxis(ax):\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    ax.get_xaxis().tick_bottom()\n    ax.get_yaxis().tick_left()\n\ndef day_format(label):\n    \"\"\"\n    Convert time label to the format of pandas line plot\n    \"\"\"\n    return f'{label.month} {label.day}'\n\ndef month_format(label):\n    \"\"\"\n    Convert time label to the format of pandas line plot\n    \"\"\"\n    month = label.month_name()[:3]\n    if month == 'Jan':\n        month = month + '\\n' + f'{label.year}'\n    #else:\n    #    month = \"\"\n    return month\n\ndef quarter_format(label):\n    \"\"\"\n    Convert time label to the format of pandas line plot\n    \"\"\"\n    month = label.month_name()[:3]\n    if month == 'Jan':\n        month = f'Q1\\n{label.year}'\n    if month == 'Apr':\n        month = 'Q2'\n    if month == 'Jul':\n        month = 'Q3'\n    if month == 'Oct':\n        month = 'Q4'\n    return month\n\n\n\n\nNow we will read in some data.\n\n### Quarterly\n\nFREDmap = {\n    'GDPC1': 'real_gdp'\n    }\n\nquarterly = pdr.DataReader(list(FREDmap.keys()), 'fred', datetime.datetime(1800,1,1))\nquarterly.rename(columns = FREDmap, inplace = True)\n\nquarterly.to_pickle('quarterly.pickle')\n\n\n\n\nquarterly['real_gdp'].tail()\n\n\n\ndef EconLineGraph(dataframe = None,\n                  series = None,\n                  labels = None,\n                  title = None,\n                  subtitle = None,\n                  source = None,\n                  ylabel = None,\n                  start_date = None,\n                  end_date = None,\n                  graph_name = None,\n                  recessions = False,\n                  logscale = False,\n                  ylines = None,\n                  yzero = False):\n   \"\"\"For creating line graphs from a data frame\n\n    Inputs:\n    -------\n    dataframe : dataframe\n         The dataframe containing the data to be plotted                           \n    series : vector of text\n         The \"names\" of the variables to be plotted\n    labels : vector of text\n         The labels (descriptions) of each variable\n    title : text string\n         Title for the figure\n    subtitle : text string\n         A \"title\" which appears at top left of the figure\n    source : text string\n         The source for the data; appears at bottom right of the figure\n    ylabel : text string\n         Text that appears beside the y axis\n    start_date : string\n         The first date to appear in the figure (end date is always the last available\n         observation). String as 'yyyy-mm-dd'.\n    graph_name : text string\n         The basename for the graph files. Both pdf and png files are produced\n    recessions : logical\n         If True, then include NBER business cycle recession shading from \n         the dataframe \"monthly\"\n    \"\"\"\n    \n   if start_date == None:\n      df = dataframe[series].dropna(how = 'all')\n      start_date = df.first_valid_index()\n   else:\n      df = dataframe.loc[start_date:][series].dropna(how = 'all')\n\n   fig, ax = plt.subplots()\n       \n   if logscale:\n      ax.set_yscale('log')\n      ax.yaxis.set_major_formatter(plt.FormatStrFormatter(\"%.0f\"))\n      ax.yaxis.set_minor_formatter(plt.FormatStrFormatter(\"%.0f\"))\n\n   if recessions:\n      ax.plot(df, clip_on = False)\n   else:\n      df.plot(ax = ax, clip_on = False)\n\n   if yzero is True:\n      plt.axhline(y = 0, color = '#a0a0a0', linewidth = 0.75, label = None)\n   else:\n      if ylines is not None:\n         if len(ylines) == 1:\n            df[str(ylines)] = ylines[0]\n            df[str(ylines)].loc[start_date:].plot(ax = ax, clip_on = False, color = '#a0a0a0', linewidth = 1.0)\n         else:\n            for i in ylines:\n               df[str(i)] = i\n               df[str(i)].loc[start_date:].plot(ax = ax, clip_on = False, color = '#a0a0a0', linewidth = 1.0)\n      \n   if title is not None:\n      ax.set_title(title)\n\n   if subtitle is not None:\n      ax.set_title(subtitle,\n                   loc = 'left',\n                   color = 'black',\n                   size = 'medium')\n\n   if ylabel is not None:\n      ax.set_ylabel(ylabel)\n\n   if labels is not None:\n      #if ax.get_legend() != None:\n      ax.legend(labels)\n      #ax.legend().set_zorder(2)\n   else:\n      if ax.get_legend() != None:\n         ax.legend().set_visible(False)\n\n   if source is not None:\n      ax.set_xlabel('Source: ' + source,\n                    horizontalalignment='right',\n                    x=1.0)\n   else:\n      ax.set_xlabel('')\n\n   if recessions:\n      ax2 = ax.twinx()\n      Recessions = monthly['recessiondates'][monthly.index >= start_date]\n      ax2.fill_between(Recessions.index,\n                       Recessions,\n                       step=\"pre\",\n                       color=\"gray\",\n                       alpha=.2)\n      ax2.get_yaxis().set_visible(False)\n      ax2.set_ymargin(0) \n\n   fig.savefig('pyfigs/pdf/' + graph_name + '.pdf', bbox_inches='tight', pad_inches=0.25)\n   fig.savefig('pyfigs/png/' + graph_name + '.png', bbox_inches='tight', pad_inches=0.25)\n   \n\n\n\n\n\nEconLineGraph(dataframe = quarterly,\n              series = ['real_gdp'],\n              title = 'Real GDP\\n',\n              subtitle = 'Billions of Chained 2017 Dollars',\n              source = 'BEA',\n              start_date = '1947-01-01',\n              graph_name = 'log_real_gdp',\n              logscale= False)\n\n\n\n\nTake the log of real gdp and create the hpfilter, using 1600 for \\lambda.\n\nquarterly['lrgdp'] = np.log(quarterly['real_gdp'])\nhpcycle_gdp, hptrend_gdp = hpfilter(quarterly['lrgdp'].dropna(), lamb=1600)\nquarterly['hptrend_gdp'] = hptrend_gdp\nquarterly['hpcycle_gdp'] = hpcycle_gdp\n\n\n\nNow graph the real gdp series and the hp trend.\n\nEconLineGraph(dataframe = quarterly,\n          series = ['lrgdp', 'hptrend_gdp'],\n          labels = ['GDP', 'HP Trend'],\n          title = 'Real GDP and HP Trend\\n',\n          subtitle = 'Log of Trillions of 2017 Dollars',\n          source = 'BEA',\n          start_date = '1947-01-01',\n          graph_name = 'hp_log_real_gdp',\n          logscale= False)\n\n\n\n\n\n\n\nEconLineGraph(dataframe = quarterly,\n          series = ['hpcycle_gdp'],\n          title = 'Real GDP Cyclical Component\\n',\n          subtitle = 'Log of Trillions of 2017 Dollars',\n          source = 'BEA',\n          start_date = '1947-01-01',\n          graph_name = 'hp_cycle_log_real_gdp',\n          yzero = True,\n          logscale= False)\n\n\n\nHomework #1:\n\n(A) Use a very large number for \\lambda, like 16000000000 and see the trend and cycle. Explain what is going on. Next plot the cylical component for the two different \\lambdaâ€™s and comment on the difference.\n\n(B) Download GDPCA from FRED. This is annual real GDP back to 1929. Should you use \\lambda=1600? Why or why not? If not, what value should you use? Why?","type":"content","url":"/hp1","position":1},{"hierarchy":{"lvl1":"Econ 204 Lecture Notes"},"type":"lvl1","url":"/","position":0},{"hierarchy":{"lvl1":"Econ 204 Lecture Notes"},"content":"Welcome! This site contains lecture notebooks and notes for Econ 204.\n\nUse the ðŸ“‹ button to copy code from cells.\n\nEach lecture is listed in the table of contents.","type":"content","url":"/","position":1}]}